{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "options.headless = False \n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-extensions\")\n",
    "options.add_argument(\"--start-maximized\")\n",
    "options.add_argument(\"disable-infobars\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "\n",
    "url = \"https://www.zara.com/de/de/woman-must-have-l4108.html?v1=2420954\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(url)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wait = WebDriverWait(driver, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m         last_height \u001b[38;5;241m=\u001b[39m new_height\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Perform gradual scrolling with pauses and small steps\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[43mgradual_scroll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpause_time\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Additional wait to ensure that all content has been loaded\u001b[39;00m\n\u001b[0;32m     20\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mgradual_scroll\u001b[1;34m(driver, pause_time, step_size)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, last_height, step_size):\n\u001b[0;32m      6\u001b[0m     driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwindow.scrollTo(0, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(pause_time)\n\u001b[0;32m     10\u001b[0m new_height \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn document.body.scrollHeight\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def gradual_scroll(driver, pause_time, step_size):\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        for i in range(0, last_height, step_size):\n",
    "            driver.execute_script(f\"window.scrollTo(0, {i});\")\n",
    "            time.sleep(pause_time)\n",
    "        \n",
    "        time.sleep(pause_time)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "\n",
    "# Perform gradual scrolling with pauses and small steps\n",
    "gradual_scroll(driver, pause_time=0.2, step_size=50)\n",
    "\n",
    "# Additional wait to ensure that all content has been loaded\n",
    "time.sleep(5)\n",
    "\n",
    "# Extract the HTML from the page\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "# Save the HTML to a file for further analysis (commented out)\n",
    "# with open(\"zara_woman_blazer.html\", \"w\", encoding='utf-8') as file:\n",
    "#     file.write(page_source)\n",
    "\n",
    "print(\"Scrolling, view change, and extraction have been completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stale element, retrying... attempt 1\n",
      "Switched to iframe.\n",
      "No cookie consent banner found or timeout occurred.\n",
      "Timed out waiting for the products to load.\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, StaleElementReferenceException\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Navigate to the Zara Woman Germany webpage\n",
    "driver.get(\"https://www.zara.com/de/de/damen-neuware-l1180.html?v1=2419517\")\n",
    "\n",
    "# Retry logic in case of StaleElementReferenceException\n",
    "attempt = 0\n",
    "max_attempts = 3\n",
    "\n",
    "while attempt < max_attempts:\n",
    "    try:\n",
    "        # Check for iframe and switch to it\n",
    "        iframe = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.TAG_NAME, 'iframe'))  # Locate the iframe if present\n",
    "        )\n",
    "        driver.switch_to.frame(iframe)\n",
    "        print(\"Switched to iframe.\")\n",
    "\n",
    "        # Locate the cookie consent button inside the iframe\n",
    "        cookie_button = WebDriverWait(driver, 30).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'ALLE COOKIE')]\"))\n",
    "        )\n",
    "\n",
    "        # Add a brief wait to ensure stability before clicking (optional)\n",
    "        sleep(1)\n",
    "\n",
    "        # Click the cookie consent button\n",
    "        cookie_button.click()\n",
    "        print(\"Cookie consent accepted.\")\n",
    "\n",
    "        # Switch back to the default content after interacting with the iframe\n",
    "        driver.switch_to.default_content()\n",
    "\n",
    "        # Exit the loop as the task was successful\n",
    "        break\n",
    "\n",
    "    except StaleElementReferenceException:\n",
    "        print(f\"Stale element, retrying... attempt {attempt + 1}\")\n",
    "        attempt += 1\n",
    "        driver.switch_to.default_content()  # Ensure we return to the default content before retrying\n",
    "\n",
    "    except TimeoutException:\n",
    "        print(\"No cookie consent banner found or timeout occurred.\")\n",
    "        break\n",
    "\n",
    "if attempt == max_attempts:\n",
    "    print(f\"Failed after {max_attempts} attempts.\")\n",
    "\n",
    "# Now proceed with your scraping logic or further interactions\n",
    "try:\n",
    "    # Example of waiting for the product items to load (adjust the class name)\n",
    "    WebDriverWait(driver, 30).until(\n",
    "        EC.presence_of_all_elements_located((By.CLASS_NAME, 'correct-product-item-class'))\n",
    "    )\n",
    "    print(\"Products loaded successfully.\")\n",
    "except TimeoutException:\n",
    "    print(\"Timed out waiting for the products to load.\")\n",
    "\n",
    "# Close the driver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height = driver.execute_script(\"return document.documentElement.scrollHeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = soup.find_all('li', class_='product-grid-product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"Categoria\":[],\n",
    "    \"Sexo\": [], \n",
    "    \"Producto\": [],\n",
    "    \"Color\": [],\n",
    "    \"Subcategoría\": [],\n",
    "    \"Referencia\": [],\n",
    "    \"Precio\": [],\n",
    "    \"Imagen\": [],\n",
    "    \"Link\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for product in products:\n",
    "    # Extraer el nombre y color del producto desde el atributo 'alt' de <img>\n",
    "    image_tag = product.find('img', class_='media-image__image')\n",
    "    if image_tag and 'alt' in image_tag.attrs:\n",
    "        alt_text = image_tag['alt']\n",
    "        # Verificar si se puede dividir en dos partes: nombre y color\n",
    "        split_text = alt_text.split(' - ')\n",
    "        if len(split_text) == 2:\n",
    "            name, color = split_text\n",
    "        else:\n",
    "            name = alt_text  # Si no hay un guion, tomamos todo como el nombre\n",
    "            color = \"No Color\"  # Color por defecto\n",
    "    else:\n",
    "        name = \"No Name\"\n",
    "        color = \"No Color\"\n",
    "    \n",
    "    # Extraer el enlace al producto desde el <a> con clase 'product-link'\n",
    "    link = product.find('a', class_='product-link')['href'] if product.find('a', class_='product-link') else \"No Link\"\n",
    "    \n",
    "    # Extraer la subcategoría desde el link, basándonos en palabras clave\n",
    "    subcategory = link.split('/')[-1].split('-')[0]  # Primera palabra de la URL del producto (ej. \"capa\")\n",
    "\n",
    "    # Extraer el precio del producto desde el <span> con clase 'money-amount__main'\n",
    "    price = product.find('span', class_='money-amount__main').get_text(strip=True) if product.find('span', class_='money-amount__main') else \"No Price\"\n",
    "    \n",
    "    # Extraer la referencia del producto (viene como 'data-productid' en la etiqueta <li>)\n",
    "    reference = product.get('data-productid', 'No Reference')\n",
    "    \n",
    "    # Extraer la imagen del producto desde el <img> con clase 'media-image__image'\n",
    "    image = product.find('img', class_='media-image__image')['src'] if product.find('img', class_='media-image__image') else \"No Image\"\n",
    "    \n",
    "    categoria = categoria\n",
    "\n",
    "    sexo = sexo \n",
    "\n",
    "    # Guardar la información en el diccionario\n",
    "    data[\"Categoria\"].append(categoria)\n",
    "    data[\"Sexo\"].append(sexo)\n",
    "    data[\"Producto\"].append(name)\n",
    "    data[\"Color\"].append(color)\n",
    "    data[\"Subcategoría\"].append(subcategory)\n",
    "    data[\"Referencia\"].append(reference)\n",
    "    data[\"Precio\"].append(price)\n",
    "    data[\"Imagen\"].append(image)\n",
    "    data[\"Link\"].append(link)\n",
    "\n",
    "# Convertir el diccionario en un DataFrame de pandas\n",
    "df = pd.DataFrame(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
